{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings \n",
    "import re \n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.data.path.append(\"../nltk_data/\")\n",
    "porter = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec = pd.read_csv(\"../final_data/ec.csv\") #main ec\n",
    "ingre = pd.read_csv(\"../final_data/ingredient.csv\") #ingredient ec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec = ec.iloc[:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec = ec.rename(columns={ec.columns[1]: 'ec_description', ec.columns[0]: 'ec_code'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingre = ingre.rename(columns = {ingre.columns[1]:\"ec_description\", ingre.columns[0]:'ec_code'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing():\n",
    "    \n",
    "    def __init__(self,text):\n",
    "        \n",
    "        self.text = text\n",
    "    \n",
    "    def text_lowercase(self):\n",
    "        self.new_text = self.text.lower()\n",
    "        return self.new_text\n",
    "    \n",
    "    def remove_numbers(self):\n",
    "        self.new_text = re.sub('[^A-Za-z0-9]+', ' ', self.new_text)\n",
    "        return self.new_text\n",
    "    \n",
    "    def remove_punctuation(self):\n",
    "        translator = str.maketrans(\"\",\"\", string.punctuation)\n",
    "        slef.new_text = self.new_text.translate(translator)\n",
    "        return self.new_text\n",
    "    \n",
    "    def remove_characters(self):\n",
    "        self.new_text = re.sub('[^A-Za-z0-9]+', ' ', self.new_text)\n",
    "        return self.new_text\n",
    "    \n",
    "    def remove_letters(self):\n",
    "        stopwords_ = stopwords.words('english')+['rfg', 'regular',\"label\",\"private\"]\n",
    "        self.new_text = [i for i in self.new_text if len(i)> 2 if i not in stopwords_]\n",
    "        return self.new_text\n",
    "    \n",
    "    def lemmatize(self):\n",
    "        self.new_text = [lemmatizer.lemmatize(token, 'v') for token in self.new_text]\n",
    "        return self.new_text\n",
    "    \n",
    "    def remove_words(self):\n",
    "        stopwords_ = stopwords.words('english')+['rfg', 'regular',\"label\",\"private\"]\n",
    "        self.new_text = [token for token in self.new_text if token not in stopwords_]\n",
    "        return self.new_text\n",
    "\n",
    "    def tokenize(self):\n",
    "        try:\n",
    "            self.new_text = self.new_text.split(\" \")\n",
    "        except:\n",
    "            self.new_text = []\n",
    "        return self.new_text\n",
    "    \n",
    "def create_tokens(phrase):\n",
    "    pp = Preprocessing(phrase)\n",
    "    \n",
    "    pp.text_lowercase()\n",
    "    pp.remove_numbers()\n",
    "    pp.remove_characters()\n",
    "    pp.tokenize()\n",
    "    pp.remove_letters()\n",
    "    pp_tokens = pp.lemmatize()\n",
    "    pp_tokens = \" \".join(pp_tokens)\n",
    "    return pp_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the ingredient table to the main table\n",
    "# Clean the text to keep only numbers and lowercase letters\n",
    "ec_cleaned = pd.concat([ec, ingre], axis=0)\n",
    "from tqdm import tqdm\n",
    "ec_results = []\n",
    "\n",
    "for w in tqdm(ec_cleaned[\"ec_description\"]):\n",
    "    ec_results.append(create_tokens(w))\n",
    "ec_cleaned[\"ec_description\"] = ec_results\n",
    "# Some food descriptions are different across the years. They will be dropped here for now.\n",
    "# This also removes duplicate ingredient records\n",
    "ec_cleaned = ec_cleaned.drop_duplicates('ec_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppc = pd.read_csv(\"../final_data/ppc20172018_publictest.csv\") #ppc\n",
    "valid_ec = set(ppc['ec'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we don't need to specifically filter out negative EC codes because they don't exist in EC table at the first place\n",
    "ec_cleaned = ec_cleaned.loc[ec_cleaned['ec_code'].isin(valid_ec)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec_cleaned.to_csv('../final_data/1718ec_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
