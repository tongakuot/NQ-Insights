{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing EC Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook takes in the three tables from the database, and the following preprocessing is done for the EC codes:\n",
    " - Three description tables are joined to get as much description text for the EC codes as possible (main food description table, additional description table, and ingredient table). The `food_code` in additional and main food description tables and the `ingredient_code` are both EC codes, while additional description table and ingredient table may contain duplicate code records. For detailed documentation, please refer to the IRI/FNDDS/PPC data dictionary for columns specifications.\n",
    " - The text is then minimally preprocessed by lowercasing and removing special characters\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings \n",
    "import re \n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Create the full EC table\n",
    "First, it keeps the `food_code` and `main_food_description` columns in the main table, and the `food_code` and `additional_food_description` columns in the additional food table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the main food description table, use food description and category description columns\n",
    "mainfooddesc = pd.read_csv('./raw_data/mainfooddesc1718.csv', dtype=str)\n",
    "mainfooddesc['main_food_description'] = mainfooddesc['main_food_description'] + ' ' + mainfooddesc['wweia_category_description']\n",
    "mainfooddesc = mainfooddesc[['food_code', 'main_food_description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainfooddesc.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the additional food description table, concatenate all description to one per food code\n",
    "addfooddesc = pd.read_csv('./raw_data/addfooddesc1516.csv', dtype=str)\n",
    "addfooddesc = addfooddesc[['Food_code', 'Additional_food_description']]\n",
    "addfooddesc = addfooddesc.rename(columns={'Food_code': 'food_code'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the additional descriptions were grouped by the food code and joined together with each other. Then the table was left joined to the main table to get an updated main table with only one column `food_description` per food code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addfooddesc['Additional_food_description'] = addfooddesc.groupby('food_code')['Additional_food_description'].transform(lambda x: ' '.join(x))\n",
    "addfooddesc = addfooddesc.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now see the tables are alike.\n",
    "addfooddesc.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left join the additional food description to the main table, concatenate all descriptions to one col per food code\n",
    "main_df = pd.merge(mainfooddesc, addfooddesc, on='food_code', how='left')\n",
    "main_df['Additional_food_description'] = main_df['Additional_food_description'].fillna('')\n",
    "main_df['main_food_description'] = main_df['main_food_description'] + ' ' + main_df['Additional_food_description']\n",
    "main_df.drop('Additional_food_description', axis=1, inplace=True)\n",
    "main_df = main_df.rename(columns={'food_code': 'ec_code', 'main_food_description': 'ec_description'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now see a longer text for this food code, after including additional description\n",
    "main_df.loc[main_df['ec_code'] == '11111000']['ec_description'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the ingredient table was concatenated to the updated main table and all duplicates were dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the ingredient table \n",
    "fnddsingred = pd.read_csv('./raw_data/fnddsingred1516.csv', dtype=str)\n",
    "fnddsingred = fnddsingred[['ingredient_code', 'ingredient_description']]\n",
    "fnddsingred = fnddsingred.rename(columns={'ingredient_description': 'ec_description', 'ingredient_code': 'ec_code'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnddsingred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(txt):\n",
    "    return re.sub('[^A-Za-z0-9]+', ' ', str(txt).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the ingredient table to the main table\n",
    "# Clean the text to keep only numbers and lowercase letters\n",
    "ec_cleaned = pd.concat([main_df, fnddsingred], axis=0)\n",
    "ec_cleaned['ec_description'] = ec_cleaned['ec_description'].apply(clean_text)\n",
    "# Some food descriptions are different across the years. They will be dropped here for now.\n",
    "# This also removes duplicate ingredient records\n",
    "ec_cleaned = ec_cleaned.drop_duplicates('ec_code')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Keep ECs that appear in PPC table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppc = pd.read_csv('./raw_data/ppc20152016.csv', dtype=str)\n",
    "valid_ec = set(ppc['ec'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we don't need to specifically filter out negative EC codes because they don't exist in EC table at the first place\n",
    "ec_cleaned = ec_cleaned.loc[ec_cleaned['ec_code'].isin(valid_ec)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(valid_ec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec_cleaned.to_csv('ec_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
