{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Model Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook takes in the cleaned UPC and EC tables and use `recordlinkage` package to perform a very simple logistic regression model. The model is very preliminary at this stage, and just to demonstrate how the task can be done with minimum data processing and time effort. \n",
    "\n",
    "`recordlinkage` is a very convenient package for easily matching records together. Although the link can't be open in ADRF, feel free to explore more outside ADRF at: https://pypi.org/project/recordlinkage/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import recordlinkage\n",
    "from recordlinkage.index import Full\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import warnings \n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The UPC and EC tables are limited to year 2015 and 2016 as well.\n",
    "upc = pd.read_csv('upc_cleaned.csv', dtype=str)\n",
    "ec = pd.read_csv('ec_cleaned.csv', dtype=str)\n",
    "ppc = pd.read_csv('./raw_data/ppc20152016.csv', dtype=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some UPC codes in PPC table are not in UPC table. They will be filtered out here. We made sure there won't be such cases in public and private test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some UPC code in PPC table was never in UPC table. They will be filtered here for now.\n",
    "# Don't filter this on EC table because there are custom ec_code that are not in EC table.\n",
    "ppc = ppc[ppc['upc'].isin(upc['upc_code'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are around 200K unique UPC records and around 3K EC records, which makes it very expensive to match without blocking. A possible thing to do it is to use their category, or same words as a blocking method to reduce the number of linkage candidates.\n",
    "\n",
    "For simplicity and demonstration purpose, here we only sample a fraction of the table to create a subset of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppc_clipped = ppc.sample(500, random_state=2498)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip the UPC and EC tables accordingly.\n",
    "upc_set = set(ppc_clipped['upc'].tolist())\n",
    "ec_set = set(ppc_clipped['ec'].tolist())\n",
    "\n",
    "upc_clipped = upc[upc['upc_code'].isin(upc_set)]\n",
    "ec_clipped = ec[ec['ec_code'].isin(ec_set)]\n",
    "\n",
    "upc_clipped = upc_clipped.set_index('upc_code')\n",
    "ec_clipped = ec_clipped.set_index('ec_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Here we use recordlinkage package to create links and also calculate Jaro-Winkler scores\n",
    "indexer = recordlinkage.Index()\n",
    "indexer.add(Full())\n",
    "candidate_links = indexer.index(upc_clipped, ec_clipped)\n",
    "\n",
    "# Calculate pairs with the Jaro-Winkler score between food description \n",
    "comparer = recordlinkage.Compare()\n",
    "comparer.string('upc_description', 'ec_description', method='jarowinkler', label='score')\n",
    "raw_data = comparer.compute(candidate_links, upc_clipped, ec_clipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the description back to the table\n",
    "raw_data['upc'], raw_data['ec'] = zip(*raw_data.index)\n",
    "raw_data['upc_description'] = raw_data['upc'].map(upc_clipped['upc_description'].to_dict())\n",
    "raw_data['ec_description'] = raw_data['ec'].map(ec_clipped['ec_description'].to_dict())\n",
    "raw_data = raw_data.fillna('no acceptable match')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply TF-IDF to transform text into vectors\n",
    "clf = TfidfVectorizer(max_features=100)\n",
    "raw_data['desc'] = raw_data['upc_description'] + \" \" + raw_data['ec_description']\n",
    "clf.fit(raw_data['desc'])\n",
    "tfidf_vector = clf.transform(raw_data['desc']).todense()\n",
    "vector_df = pd.DataFrame(tfidf_vector, index=candidate_links)\n",
    "vector_df['score'] = raw_data['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Split the train and test set. Here we are going to use the whole dataset as the test set.\n",
    "X_train, _ = train_test_split(vector_df, test_size=0.8, random_state=2498)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the ground truth matches, and \n",
    "true_linkage = pd.MultiIndex.from_arrays([ppc_clipped['upc'].tolist(), ppc_clipped['ec'].tolist()])\n",
    "X_train_linkage = X_train.index\n",
    "match_index = X_train_linkage & true_linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "logrg = recordlinkage.LogisticRegressionClassifier(C=10)\n",
    "logrg.fit(X_train, match_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the whole dataset. \n",
    "result = logrg.prob(vector_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the top 5 matches\n",
    "result = result.groupby(level=0).nlargest(5).reset_index(level=0, drop=True).reset_index()\n",
    "result = result.rename(columns={'upc_code': 'upc', 'ec_code': 'ec', '0': 'confidence'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[['upc', 'ec']].to_csv('result/logistic_regression_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppc_clipped[['upc', 'ec']].to_csv('result/logistic_regression_ground_truth.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
